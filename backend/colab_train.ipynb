

# 1. Install Dependencies
# !pip install torch torchvision tqdm opencv-python

import os
import math
import random
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader, random_split, Subset
from PIL import Image
import torchvision.transforms as transforms
import torchvision.transforms.functional as TF
from tqdm import tqdm
from torchvision.utils import save_image

# ==========================================
# CONFIGURATION
# ==========================================
BATCH_SIZE = 8
LEARNING_RATE = 1e-4
WEIGHT_DECAY = 1e-5
EPOCHS = 20  # Increased for Colab (assuming GPU/time available)
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# Update this path after uploading data to Colab or mounting Drive
# Ex: "/content/drive/MyDrive/blurred_sharp" or "/content/blurred_sharp"
DATASET_PATH = "/content/blurred_sharp/blurred_sharp" 
CHECKPOINT_DIR = "checkpoints"
SAMPLE_DIR = "samples"

os.makedirs(CHECKPOINT_DIR, exist_ok=True)
os.makedirs(SAMPLE_DIR, exist_ok=True)

print(f"Device: {DEVICE}")

# ==========================================
# DATASET CLASS (Self-Contained)
# ==========================================
class DeblurDataset(Dataset):
    def __init__(self, root_dir, transform=None, augment=False):
        self.root_dir = root_dir
        self.transform = transform
        self.augment = augment
        
        # Handle different potential upload structures
        # Structure A: root/blurred_sharp/blurred & root/blurred_sharp/sharp
        # Structure B: root/blurred & root/sharp
        
        candidate_subPath = os.path.join(root_dir, "blurred_sharp")
        if os.path.exists(os.path.join(candidate_subPath, "blurred")):
             self.blur_dir = os.path.join(candidate_subPath, "blurred")
             self.sharp_dir = os.path.join(candidate_subPath, "sharp")
        else:
             self.blur_dir = os.path.join(root_dir, "blurred")
             self.sharp_dir = os.path.join(root_dir, "sharp")
        
        if not os.path.exists(self.blur_dir):
            raise ValueError(f"Could not find 'blurred' directory in {root_dir}")

        self.image_files = [f for f in os.listdir(self.blur_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]

    def __len__(self):
        return len(self.image_files)

    def __getitem__(self, idx):
        img_name = self.image_files[idx]
        blur_path = os.path.join(self.blur_dir, img_name)
        sharp_path = os.path.join(self.sharp_dir, img_name)

        blur_image = Image.open(blur_path).convert("RGB")
        sharp_image = Image.open(sharp_path).convert("RGB")

        resize = transforms.Resize((256, 256))
        blur_image = resize(blur_image)
        sharp_image = resize(sharp_image)

        if self.augment:
            if random.random() > 0.5:
                blur_image = TF.hflip(blur_image)
                sharp_image = TF.hflip(sharp_image)
            if random.random() > 0.5:
                blur_image = TF.vflip(blur_image)
                sharp_image = TF.vflip(sharp_image)

        to_tensor = transforms.ToTensor()
        blur_image = to_tensor(blur_image)
        sharp_image = to_tensor(sharp_image)

        return blur_image, sharp_image

# ==========================================
# MODEL CLASS (Self-Contained)
# ==========================================
class DoubleConv(nn.Module):
    def __init__(self, in_channels, out_channels, mid_channels=None):
        super().__init__()
        if not mid_channels:
            mid_channels = out_channels
        self.double_conv = nn.Sequential(
            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),
            nn.BatchNorm2d(mid_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True)
        )

    def forward(self, x):
        return self.double_conv(x)

class Down(nn.Module):
    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.maxpool_conv = nn.Sequential(
            nn.MaxPool2d(2),
            DoubleConv(in_channels, out_channels)
        )

    def forward(self, x):
        return self.maxpool_conv(x)

class Up(nn.Module):
    def __init__(self, in_channels, out_channels, bilinear=True):
        super().__init__()
        if bilinear:
            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)
            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)
        else:
            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)
            self.conv = DoubleConv(in_channels, out_channels)

    def forward(self, x1, x2):
        x1 = self.up(x1)
        diffY = x2.size()[2] - x1.size()[2]
        diffX = x2.size()[3] - x1.size()[3]
        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,
                        diffY // 2, diffY - diffY // 2])
        x = torch.cat([x2, x1], dim=1)
        return self.conv(x)

class OutConv(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(OutConv, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)

    def forward(self, x):
        return self.conv(x)

class DeblurUNet(nn.Module):
    def __init__(self, n_channels=3, n_classes=3, bilinear=False):
        super(DeblurUNet, self).__init__()
        self.n_channels = n_channels
        self.n_classes = n_classes
        self.inc = DoubleConv(n_channels, 32)
        self.down1 = Down(32, 64)
        self.down2 = Down(64, 128)
        self.down3 = Down(128, 256)
        factor = 2 if bilinear else 1
        self.down4 = Down(256, 512 // factor)
        self.up1 = Up(512, 256 // factor, bilinear)
        self.up2 = Up(256, 128 // factor, bilinear)
        self.up3 = Up(128, 64 // factor, bilinear)
        self.up4 = Up(64, 32, bilinear)
        self.outc = OutConv(32, n_classes)

    def forward(self, x):
        x1 = self.inc(x)
        x2 = self.down1(x1)
        x3 = self.down2(x2)
        x4 = self.down3(x3)
        x5 = self.down4(x4)
        x = self.up1(x5, x4)
        x = self.up2(x, x3)
        x = self.up3(x, x2)
        x = self.up4(x, x1)
        logits = self.outc(x)
        return torch.sigmoid(logits)

# ==========================================
# TRAINING LOOPS
# ==========================================
def train_one_epoch(model, loader, criterion, optimizer, device):
    model.train()
    running_loss = 0.0
    loop = tqdm(loader, desc="Training")
    
    for blur_imgs, sharp_imgs in loop:
        blur_imgs = blur_imgs.to(device)
        sharp_imgs = sharp_imgs.to(device)
        
        outputs = model(blur_imgs)
        loss = criterion(outputs, sharp_imgs)
        
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
        running_loss += loss.item()
        loop.set_postfix(loss=loss.item())
        
    return running_loss / len(loader)

def validate(model, loader, criterion, device, epoch):
    model.eval()
    running_loss = 0.0
    with torch.no_grad():
        for i, (blur_imgs, sharp_imgs) in enumerate(loader):
            blur_imgs = blur_imgs.to(device)
            sharp_imgs = sharp_imgs.to(device)
            
            outputs = model(blur_imgs)
            loss = criterion(outputs, sharp_imgs)
            running_loss += loss.item()
            
            if i == 0:
                comparison = torch.cat([blur_imgs[:4], outputs[:4], sharp_imgs[:4]], dim=0)
                save_image(comparison, f"{SAMPLE_DIR}/epoch_{epoch}.png", nrow=4)
                
    return running_loss / len(loader)

# ==========================================
# MAIN EXECUTION
# ==========================================
def main():
    print("Initializing...")
    try:
        temp_dataset = DeblurDataset(root_dir=DATASET_PATH)
    except Exception as e:
        print(f"Error loading dataset: {e}")
        print("Please check DATASET_PATH configuration.")
        return

    total_len = len(temp_dataset)
    train_size = int(0.9 * total_len)
    val_size = total_len - train_size
    
    indices = list(range(total_len))
    np.random.seed(42)
    np.random.shuffle(indices)
    
    train_indices = indices[:train_size]
    val_indices = indices[train_size:]
    
    # Train set with Augmentation
    train_dataset_full = DeblurDataset(root_dir=DATASET_PATH, augment=True)
    train_ds = Subset(train_dataset_full, train_indices)
    
    # Val set Pure
    val_dataset_full = DeblurDataset(root_dir=DATASET_PATH, augment=False)
    val_ds = Subset(val_dataset_full, val_indices)
    
    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)
    
    print(f"Training on {len(train_ds)} images, validating on {len(val_ds)} images")

    model = DeblurUNet().to(DEVICE)
    if os.path.exists(os.path.join(CHECKPOINT_DIR, "best_model.pth")):
         print("Resuming from checkpoint (if uploaded)...")
         try:
             model.load_state_dict(torch.load(os.path.join(CHECKPOINT_DIR, "best_model.pth")))
         except:
             print("Could not load checkpoint, starting fresh.")

    criterion = nn.L1Loss()
    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)
    
    best_loss = float('inf')
    
    for epoch in range(EPOCHS):
        print(f"Epoch {epoch+1}/{EPOCHS}")
        train_loss = train_one_epoch(model, train_loader, criterion, optimizer, DEVICE)
        val_loss = validate(model, val_loader, criterion, DEVICE, epoch+1)
        
        print(f"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}")
        
        if val_loss < best_loss:
            best_loss = val_loss
            print("Saving best model...")
            torch.save(model.state_dict(), os.path.join(CHECKPOINT_DIR, "best_model.pth"))

    print("Training Complete. Download 'checkpoints/best_model.pth' and use it in your local app.")

if __name__ == "__main__":
    main()
